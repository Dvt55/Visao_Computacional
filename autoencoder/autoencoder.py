# -*- coding: utf-8 -*-
"""autoencoder.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sre9IRyv1UsJRQXUr-fld68-JpzAv9Ot
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist

# Carregar o conjunto de dados MNIST
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalizar os dados para valores entre 0 e 1
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

X_train = x_train.reshape(-1, 28, 28, 1)
X_test = x_test.reshape(-1, 28, 28, 1)

# Definir o Autoencoder
model = models.Sequential()

# Encoder
model.add(layers.Input(shape=(28, 28, 1)))  # Entrada da imagem
model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(layers.MaxPooling2D((2, 2), padding='same'))
model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(layers.MaxPooling2D((2, 2), padding='same'))
model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))

# Decoder
model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(layers.UpSampling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(layers.UpSampling2D((2, 2)))
model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))  # Saída com 1 canal

# Compilar o modelo
model.compile(optimizer='adam', loss='binary_crossentropy')
model.summary()  # Mostrar resumo do modelo

# Treinamento do Autoencoder
model.fit(x_train, x_train, epochs=2, batch_size=256, shuffle=True, validation_data=(x_test, x_test))

# Função para colorir os dígitos
def colorize_digits(decoded_imgs, labels):
    colorized_imgs = np.zeros((decoded_imgs.shape[0], 28, 28, 3))  # 3 canais de cor (RGB)

    for i in range(decoded_imgs.shape[0]):
        if labels[i] % 2 == 0:
            colorized_imgs[i, :, :, 2] = decoded_imgs[i, :, :, 0]  # Canal azul
        else:
            colorized_imgs[i, :, :, 0] = decoded_imgs[i, :, :, 0]  # Canal vermelho

    return colorized_imgs

# Reconstruir e colorir as imagens
decoded_imgs = model.predict(x_test)
colorized_imgs = colorize_digits(decoded_imgs, y_test)

# Visualização dos resultados
n = 10  # número de imagens para mostrar
plt.figure(figsize=(20, 4))
for i in range(n):
    # Imagens originais em grayscale
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    plt.title(f"Original {y_test[i]}")
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Imagens coloridas
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(colorized_imgs[i])
    plt.title(f"Colorized {y_test[i]}")
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

plt.show()

